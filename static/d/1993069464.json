{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"friendlyName":"Branch and Bound on Cost","solverKey":"branchAndBoundOnCost","type":"algorithm","class":"exhaustive"},"html":"<p>When deploying a set of services using docker-compose, it’s a good idea to have a separate repository to avoid cloning all of the code into your production environment.</p>\n<p>I finally got <a href=\"https://www.term.ninja\">termninja</a> set up correctly with continuous integration and docker-compose on digital ocean, and I thought I’d document the setup.</p>\n<h2>Production repository</h2>\n<p>A typical docker-compose project has a <code class=\"language-text\">docker-compose.yml</code> at the root of the project, and all of the code for the images as subfolders.</p>\n<p>[development folder structure]</p>\n<p>This works great for development - it’s easy to set up volumes and edit the code alongside the images. In production, however, it doesn’t make sense to clone the entire repository just to get to the docker-compose.yml file and start services.</p>\n<p>The solution I prefer is to have a separate repository set-up, in this case termninja-docker, that contains only the docker-compose.yml and any production specific configuration.</p>\n<p>[production folder structure]</p>\n<h2>Deployment</h2>\n<p>With this structure in place, deployments are accomplished using a container registry (like <a href=\"docker.com/hub\">docker hub</a>). It’s free to use for public images, and easy to push with docker-compose.</p>\n<p>The docker-compose.yml in both the development repo and the production repo should be setup to track the container registry.</p>\n<p>[tagged docker-compose]</p>\n<h2>Building and pushing images</h2>\n<p>Once the docker-compose.yml file is setup to track the appropriate image from the container registry, building images is simple.</p>\n<p><code class=\"language-text\">docker-compose build [service-name]</code></p>\n<p>Pushing the updated image is equally simple</p>\n<p><code class=\"language-text\">docker-compose push [service-name]</code></p>\n<h2>Pulling latest images</h2>\n<p>From the production environment, once the production docker-compose.yml is setup to track the container registry images, updating is simple</p>\n<p><code class=\"language-text\">docker-compose down</code>\n<code class=\"language-text\">docker-compose pull [service-name]</code>\n<code class=\"language-text\">docker-compose up</code></p>\n<p>All of this seems very intuitive, but I’ve come across several projects where deployments are setup to:\nclone the development repo\nbuild and start images</p>\n<p>This process is time consuming (more downtime) and results in unnecessary code residing on the server.</p>\n<h2>Continuous integration</h2>\n<p>Once this process is in place, I recommend setting up continuous integration to perform these functions automatically on every commit to the master branch in the development repo. </p>\n<p>A simplified travis-ci configuration from <a href=\"https://www.term.ninja\">termninja</a> is below. It performs the following steps on every commit.</p>\n<ol>\n<li>Clone the repository (automatic for travis)</li>\n<li>Login to docker hub using credentials provided through the <a href=\"https://www.travis-ci.com/environment\">travis environment</a> - <code class=\"language-text\">docker login</code></li>\n<li>Build the services - <code class=\"language-text\">docker-compose build games api</code></li>\n<li>Push the images - <code class=\"language-text\">docker-compose push games api</code></li>\n<li>Decrypt private production SSH key*</li>\n<li>SSH to production environmnet</li>\n<li>Stop services - <code class=\"language-text\">docker-compose down</code></li>\n<li>Pull updated images - <code class=\"language-text\">docker-compose pull games api</code></li>\n<li>Start service - <code class=\"language-text\">docker-compose up</code></li>\n</ol>\n<p>[travis-ci.yml]</p>\n<p>*Note that the ssh keys for the production server must be <a href=\"https://travis-ci.com/ssh-keys\">encrypted</a>.</p>\n<p>Hopefully this helps someone else as there was less documentation out there than I expected when setting this up. Let me know how it goes below, thanks!</p>"}},{"node":{"frontmatter":{"friendlyName":"Random","solverKey":"random","type":"algorithm","class":"exhaustive"},"html":"<p>When deploying a set of services using docker-compose, it’s a good idea to have a separate repository to avoid cloning all of the code into your production environment.</p>\n<p>I finally got <a href=\"https://www.term.ninja\">termninja</a> set up correctly with continuous integration and docker-compose on digital ocean, and I thought I’d document the setup.</p>\n<h2>Production repository</h2>\n<p>A typical docker-compose project has a <code class=\"language-text\">docker-compose.yml</code> at the root of the project, and all of the code for the images as subfolders.</p>\n<p>[development folder structure]</p>\n<p>This works great for development - it’s easy to set up volumes and edit the code alongside the images. In production, however, it doesn’t make sense to clone the entire repository just to get to the docker-compose.yml file and start services.</p>\n<p>The solution I prefer is to have a separate repository set-up, in this case termninja-docker, that contains only the docker-compose.yml and any production specific configuration.</p>\n<p>[production folder structure]</p>\n<h2>Deployment</h2>\n<p>With this structure in place, deployments are accomplished using a container registry (like <a href=\"docker.com/hub\">docker hub</a>). It’s free to use for public images, and easy to push with docker-compose.</p>\n<p>The docker-compose.yml in both the development repo and the production repo should be setup to track the container registry.</p>\n<p>[tagged docker-compose]</p>\n<h2>Building and pushing images</h2>\n<p>Once the docker-compose.yml file is setup to track the appropriate image from the container registry, building images is simple.</p>\n<p><code class=\"language-text\">docker-compose build [service-name]</code></p>\n<p>Pushing the updated image is equally simple</p>\n<p><code class=\"language-text\">docker-compose push [service-name]</code></p>\n<h2>Pulling latest images</h2>\n<p>From the production environment, once the production docker-compose.yml is setup to track the container registry images, updating is simple</p>\n<p><code class=\"language-text\">docker-compose down</code>\n<code class=\"language-text\">docker-compose pull [service-name]</code>\n<code class=\"language-text\">docker-compose up</code></p>\n<p>All of this seems very intuitive, but I’ve come across several projects where deployments are setup to:\nclone the development repo\nbuild and start images</p>\n<p>This process is time consuming (more downtime) and results in unnecessary code residing on the server.</p>\n<h2>Continuous integration</h2>\n<p>Once this process is in place, I recommend setting up continuous integration to perform these functions automatically on every commit to the master branch in the development repo. </p>\n<p>A simplified travis-ci configuration from <a href=\"https://www.term.ninja\">termninja</a> is below. It performs the following steps on every commit.</p>\n<ol>\n<li>Clone the repository (automatic for travis)</li>\n<li>Login to docker hub using credentials provided through the <a href=\"https://www.travis-ci.com/environment\">travis environment</a> - <code class=\"language-text\">docker login</code></li>\n<li>Build the services - <code class=\"language-text\">docker-compose build games api</code></li>\n<li>Push the images - <code class=\"language-text\">docker-compose push games api</code></li>\n<li>Decrypt private production SSH key*</li>\n<li>SSH to production environmnet</li>\n<li>Stop services - <code class=\"language-text\">docker-compose down</code></li>\n<li>Pull updated images - <code class=\"language-text\">docker-compose pull games api</code></li>\n<li>Start service - <code class=\"language-text\">docker-compose up</code></li>\n</ol>\n<p>[travis-ci.yml]</p>\n<p>*Note that the ssh keys for the production server must be <a href=\"https://travis-ci.com/ssh-keys\">encrypted</a>.</p>\n<p>Hopefully this helps someone else as there was less documentation out there than I expected when setting this up. Let me know how it goes below, thanks!</p>"}},{"node":{"frontmatter":{"friendlyName":"Depth First Search (Brute Force)","solverKey":"depthFirstSearch","type":"algorithm","class":"exhaustive"},"html":"<p>When deploying a set of services using docker-compose, it’s a good idea to have a separate repository to avoid cloning all of the code into your production environment.</p>\n<p>I finally got <a href=\"https://www.term.ninja\">termninja</a> set up correctly with continuous integration and docker-compose on digital ocean, and I thought I’d document the setup.</p>\n<h2>Production repository</h2>\n<p>A typical docker-compose project has a <code class=\"language-text\">docker-compose.yml</code> at the root of the project, and all of the code for the images as subfolders.</p>\n<p>[development folder structure]</p>\n<p>This works great for development - it’s easy to set up volumes and edit the code alongside the images. In production, however, it doesn’t make sense to clone the entire repository just to get to the docker-compose.yml file and start services.</p>\n<p>The solution I prefer is to have a separate repository set-up, in this case termninja-docker, that contains only the docker-compose.yml and any production specific configuration.</p>\n<p>[production folder structure]</p>\n<h2>Deployment</h2>\n<p>With this structure in place, deployments are accomplished using a container registry (like <a href=\"docker.com/hub\">docker hub</a>). It’s free to use for public images, and easy to push with docker-compose.</p>\n<p>The docker-compose.yml in both the development repo and the production repo should be setup to track the container registry.</p>\n<p>[tagged docker-compose]</p>\n<h2>Building and pushing images</h2>\n<p>Once the docker-compose.yml file is setup to track the appropriate image from the container registry, building images is simple.</p>\n<p><code class=\"language-text\">docker-compose build [service-name]</code></p>\n<p>Pushing the updated image is equally simple</p>\n<p><code class=\"language-text\">docker-compose push [service-name]</code></p>\n<h2>Pulling latest images</h2>\n<p>From the production environment, once the production docker-compose.yml is setup to track the container registry images, updating is simple</p>\n<p><code class=\"language-text\">docker-compose down</code>\n<code class=\"language-text\">docker-compose pull [service-name]</code>\n<code class=\"language-text\">docker-compose up</code></p>\n<p>All of this seems very intuitive, but I’ve come across several projects where deployments are setup to:\nclone the development repo\nbuild and start images</p>\n<p>This process is time consuming (more downtime) and results in unnecessary code residing on the server.</p>\n<h2>Continuous integration</h2>\n<p>Once this process is in place, I recommend setting up continuous integration to perform these functions automatically on every commit to the master branch in the development repo. </p>\n<p>A simplified travis-ci configuration from <a href=\"https://www.term.ninja\">termninja</a> is below. It performs the following steps on every commit.</p>\n<ol>\n<li>Clone the repository (automatic for travis)</li>\n<li>Login to docker hub using credentials provided through the <a href=\"https://www.travis-ci.com/environment\">travis environment</a> - <code class=\"language-text\">docker login</code></li>\n<li>Build the services - <code class=\"language-text\">docker-compose build games api</code></li>\n<li>Push the images - <code class=\"language-text\">docker-compose push games api</code></li>\n<li>Decrypt private production SSH key*</li>\n<li>SSH to production environmnet</li>\n<li>Stop services - <code class=\"language-text\">docker-compose down</code></li>\n<li>Pull updated images - <code class=\"language-text\">docker-compose pull games api</code></li>\n<li>Start service - <code class=\"language-text\">docker-compose up</code></li>\n</ol>\n<p>[travis-ci.yml]</p>\n<p>*Note that the ssh keys for the production server must be <a href=\"https://travis-ci.com/ssh-keys\">encrypted</a>.</p>\n<p>Hopefully this helps someone else as there was less documentation out there than I expected when setting this up. Let me know how it goes below, thanks!</p>"}},{"node":{"frontmatter":{"friendlyName":"Shortest Path","solverKey":"shortestPath","type":"algorithm","class":"heuristic"},"html":"<p>When deploying a set of services using docker-compose, it’s a good idea to have a separate repository to avoid cloning all of the code into your production environment.</p>\n<p>I finally got <a href=\"https://www.term.ninja\">termninja</a> set up correctly with continuous integration and docker-compose on digital ocean, and I thought I’d document the setup.</p>\n<h2>Production repository</h2>\n<p>A typical docker-compose project has a <code class=\"language-text\">docker-compose.yml</code> at the root of the project, and all of the code for the images as subfolders.</p>\n<p>[development folder structure]</p>\n<p>This works great for development - it’s easy to set up volumes and edit the code alongside the images. In production, however, it doesn’t make sense to clone the entire repository just to get to the docker-compose.yml file and start services.</p>\n<p>The solution I prefer is to have a separate repository set-up, in this case termninja-docker, that contains only the docker-compose.yml and any production specific configuration.</p>\n<p>[production folder structure]</p>\n<h2>Deployment</h2>\n<p>With this structure in place, deployments are accomplished using a container registry (like <a href=\"docker.com/hub\">docker hub</a>). It’s free to use for public images, and easy to push with docker-compose.</p>\n<p>The docker-compose.yml in both the development repo and the production repo should be setup to track the container registry.</p>\n<p>[tagged docker-compose]</p>\n<h2>Building and pushing images</h2>\n<p>Once the docker-compose.yml file is setup to track the appropriate image from the container registry, building images is simple.</p>\n<p><code class=\"language-text\">docker-compose build [service-name]</code></p>\n<p>Pushing the updated image is equally simple</p>\n<p><code class=\"language-text\">docker-compose push [service-name]</code></p>\n<h2>Pulling latest images</h2>\n<p>From the production environment, once the production docker-compose.yml is setup to track the container registry images, updating is simple</p>\n<p><code class=\"language-text\">docker-compose down</code>\n<code class=\"language-text\">docker-compose pull [service-name]</code>\n<code class=\"language-text\">docker-compose up</code></p>\n<p>All of this seems very intuitive, but I’ve come across several projects where deployments are setup to:\nclone the development repo\nbuild and start images</p>\n<p>This process is time consuming (more downtime) and results in unnecessary code residing on the server.</p>\n<h2>Continuous integration</h2>\n<p>Once this process is in place, I recommend setting up continuous integration to perform these functions automatically on every commit to the master branch in the development repo. </p>\n<p>A simplified travis-ci configuration from <a href=\"https://www.term.ninja\">termninja</a> is below. It performs the following steps on every commit.</p>\n<ol>\n<li>Clone the repository (automatic for travis)</li>\n<li>Login to docker hub using credentials provided through the <a href=\"https://www.travis-ci.com/environment\">travis environment</a> - <code class=\"language-text\">docker login</code></li>\n<li>Build the services - <code class=\"language-text\">docker-compose build games api</code></li>\n<li>Push the images - <code class=\"language-text\">docker-compose push games api</code></li>\n<li>Decrypt private production SSH key*</li>\n<li>SSH to production environmnet</li>\n<li>Stop services - <code class=\"language-text\">docker-compose down</code></li>\n<li>Pull updated images - <code class=\"language-text\">docker-compose pull games api</code></li>\n<li>Start service - <code class=\"language-text\">docker-compose up</code></li>\n</ol>\n<p>[travis-ci.yml]</p>\n<p>*Note that the ssh keys for the production server must be <a href=\"https://travis-ci.com/ssh-keys\">encrypted</a>.</p>\n<p>Hopefully this helps someone else as there was less documentation out there than I expected when setting this up. Let me know how it goes below, thanks!</p>"}},{"node":{"frontmatter":{"friendlyName":"Two Opt Reciprocal Exchange","solverKey":"twoOptReciprocalExchange","type":"algorithm","class":"heuristic"},"html":"<p>When deploying a set of services using docker-compose, it’s a good idea to have a separate repository to avoid cloning all of the code into your production environment.</p>\n<p>I finally got <a href=\"https://www.term.ninja\">termninja</a> set up correctly with continuous integration and docker-compose on digital ocean, and I thought I’d document the setup.</p>\n<h2>Production repository</h2>\n<p>A typical docker-compose project has a <code class=\"language-text\">docker-compose.yml</code> at the root of the project, and all of the code for the images as subfolders.</p>\n<p>[development folder structure]</p>\n<p>This works great for development - it’s easy to set up volumes and edit the code alongside the images. In production, however, it doesn’t make sense to clone the entire repository just to get to the docker-compose.yml file and start services.</p>\n<p>The solution I prefer is to have a separate repository set-up, in this case termninja-docker, that contains only the docker-compose.yml and any production specific configuration.</p>\n<p>[production folder structure]</p>\n<h2>Deployment</h2>\n<p>With this structure in place, deployments are accomplished using a container registry (like <a href=\"docker.com/hub\">docker hub</a>). It’s free to use for public images, and easy to push with docker-compose.</p>\n<p>The docker-compose.yml in both the development repo and the production repo should be setup to track the container registry.</p>\n<p>[tagged docker-compose]</p>\n<h2>Building and pushing images</h2>\n<p>Once the docker-compose.yml file is setup to track the appropriate image from the container registry, building images is simple.</p>\n<p><code class=\"language-text\">docker-compose build [service-name]</code></p>\n<p>Pushing the updated image is equally simple</p>\n<p><code class=\"language-text\">docker-compose push [service-name]</code></p>\n<h2>Pulling latest images</h2>\n<p>From the production environment, once the production docker-compose.yml is setup to track the container registry images, updating is simple</p>\n<p><code class=\"language-text\">docker-compose down</code>\n<code class=\"language-text\">docker-compose pull [service-name]</code>\n<code class=\"language-text\">docker-compose up</code></p>\n<p>All of this seems very intuitive, but I’ve come across several projects where deployments are setup to:\nclone the development repo\nbuild and start images</p>\n<p>This process is time consuming (more downtime) and results in unnecessary code residing on the server.</p>\n<h2>Continuous integration</h2>\n<p>Once this process is in place, I recommend setting up continuous integration to perform these functions automatically on every commit to the master branch in the development repo. </p>\n<p>A simplified travis-ci configuration from <a href=\"https://www.term.ninja\">termninja</a> is below. It performs the following steps on every commit.</p>\n<ol>\n<li>Clone the repository (automatic for travis)</li>\n<li>Login to docker hub using credentials provided through the <a href=\"https://www.travis-ci.com/environment\">travis environment</a> - <code class=\"language-text\">docker login</code></li>\n<li>Build the services - <code class=\"language-text\">docker-compose build games api</code></li>\n<li>Push the images - <code class=\"language-text\">docker-compose push games api</code></li>\n<li>Decrypt private production SSH key*</li>\n<li>SSH to production environmnet</li>\n<li>Stop services - <code class=\"language-text\">docker-compose down</code></li>\n<li>Pull updated images - <code class=\"language-text\">docker-compose pull games api</code></li>\n<li>Start service - <code class=\"language-text\">docker-compose up</code></li>\n</ol>\n<p>[travis-ci.yml]</p>\n<p>*Note that the ssh keys for the production server must be <a href=\"https://travis-ci.com/ssh-keys\">encrypted</a>.</p>\n<p>Hopefully this helps someone else as there was less documentation out there than I expected when setting this up. Let me know how it goes below, thanks!</p>"}}]}}}